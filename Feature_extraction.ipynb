{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4bfbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from re import compile\n",
    "import ipaddress\n",
    "import re\n",
    "import whois\n",
    "from datetime import datetime,timezone\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7c6e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LexicalFeatures:\n",
    "    def __init__(self,url):\n",
    "        self.description = 'URL'\n",
    "        self.url = url\n",
    "        self.urlparse = urlparse(self.url)\n",
    "        self.host = self.urlparse.hostname\n",
    "        self.today = datetime.now().replace(tzinfo=None)\n",
    "        try:\n",
    "            self.whois=whois.whois(self.urlparse.netloc)\n",
    "        except:\n",
    "            self.whois=None\n",
    "    \n",
    "    def url_length(self):\n",
    "        return len(self.url)\n",
    "    \n",
    "    def url_scheme(self):\n",
    "        return self.urlparse.scheme\n",
    "    def url_path_length(self):\n",
    "        return len(self.urlparse.path)\n",
    "    def url_host_length(self):\n",
    "        return len(self.host)\n",
    "    def url_ip_address(self):\n",
    "        try:\n",
    "            ipaddress.ip_address(self.urlparse.netloc)\n",
    "            ip=1\n",
    "        except ValueError:\n",
    "            ip=0\n",
    "        return ip\n",
    "    def url_number_of_digits(self):\n",
    "        digits = [i for i in self.url if i.isdigit()]\n",
    "        return len(digits)\n",
    "    def url_number_of_parameters(self):\n",
    "        params = self.urlparse.query\n",
    "        return 0 if params == '' else len(params.split('&'))\n",
    "    def url_number_of_fragments(self):\n",
    "        frags = self.urlparse.fragment\n",
    "        return len(frags.split('#')) if frags!='' else 0\n",
    "\n",
    "    def is_url_encoded(self):\n",
    "        return '%' in self.url.lower()\n",
    "\n",
    "    def url_number_encoded_char(self):\n",
    "        encs = [i for i in self.url if i == '%']\n",
    "        return len(encs)\n",
    "\n",
    "#     def url_string_entropy(self):\n",
    "#         return self.__get_entropy(self.url)\n",
    "\n",
    "    def url_number_of_subdirectories(self):\n",
    "        d = self.urlparse.path.split('/')\n",
    "        return len(d)-1\n",
    "\n",
    "    def url_number_of_periods(self):\n",
    "        periods = [i for i in self.url if i == '.']\n",
    "        return len(periods)\n",
    "\n",
    "    def url_has_client_in_string(self):\n",
    "        return 'client' in self.url.lower()\n",
    "\n",
    "    def url_has_admin_in_string(self):\n",
    "        return 'admin' in self.url.lower()\n",
    "\n",
    "    def url_has_server_in_string(self):\n",
    "        return 'server' in self.url.lower()\n",
    "\n",
    "    def url_has_login_in_string(self):\n",
    "        return 'login' in self.url.lower()\n",
    "        \n",
    "    def url_get_tld(self):\n",
    "          return self.urlparse.netloc.split('.')[-1].split(':')[0]\n",
    "    def url_number_of_subdomains(self):\n",
    "        subdomains = len(self.urlparse.netloc.split(':')[0].split('.'))-1\n",
    "        return subdomains if subdomains>=0 else 0 \n",
    "    def url_number_of_dashes(self):\n",
    "        return 1 if len([i for i in self.urlparse.netloc if i=='-'])>0 else 0 \n",
    "    def redirection(self):\n",
    "        pos = self.url.rfind('//')\n",
    "        if pos > 6:\n",
    "            if pos > 7:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0\n",
    "    def url_have_at_sign(self):\n",
    "          return 1 if '@' in self.url else 0\n",
    "    def is_tiny_url(self):\n",
    "        #listing shortening services\n",
    "            shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "            match=re.search(shortening_services,self.url)\n",
    "            if match:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    def daysSinceRegistration(self):\n",
    "        if self.whois and self.whois['creation_date']:\n",
    "            diff = self.today - self.whois['creation_date'].replace(tzinfo=None)\n",
    "            diff = str(diff).split(' days')[0]\n",
    "            return diff\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def daysSinceExpiration(self):\n",
    "        if self.whois and self.whois['expiration_date']:\n",
    "            diff = self.whois['expiration_date'].replace(tzinfo=None) - self.today\n",
    "            diff = str(diff).split(' days')[0]\n",
    "            return diff\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def url_number_of_uppercase(self):\n",
    "        return len([i for i in self.url if i.isupper()])\n",
    "    \n",
    "    def url_number_of_spaces(self):\n",
    "        return self.url.count(\"%20\")\n",
    "    def url_number_of_zeroes(self):\n",
    "        return self.url.count('0')\n",
    "    def is_url_single_character_directory(self):\n",
    "        for i in self.urlparse.path.split('/'):\n",
    "            if len(i)==1:\n",
    "                return 1\n",
    "        return 0\n",
    "    def url_ratio_upper_to_lower(self):\n",
    "        l2=len([i for i in self.url if i.islower()])\n",
    "        return len([i for i in self.url if i.isupper()])/(l2 if l2>0 else 1000000)\n",
    "    def is_url_in_dns_record(self):\n",
    "        return 1 if not self.whois.registrar else 0\n",
    "\n",
    "    def url_web_traffic(self):\n",
    "        try:\n",
    "            url = urllib.parse.quote(self.url)\n",
    "            rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "                \"REACH\")['RANK']\n",
    "            rank = int(rank)\n",
    "            return rank\n",
    "        except TypeError:\n",
    "                return 0\n",
    "\n",
    "l = LexicalFeatures('https://www.geeksforgeeks.org/ternary-operator-in-python/');\n",
    "l.url_scheme()\n",
    "l.url_ip_address()\n",
    "l.url_number_of_digits()\n",
    "l.url_number_of_parameters()\n",
    "l.url_number_of_fragments()\n",
    "l.is_url_encoded()\n",
    "l.url_number_encoded_char()\n",
    "l.url_number_of_subdirectories()\n",
    "l.url_number_of_periods()\n",
    "l.url_has_client_in_string()\n",
    "l.url_has_server_in_string()\n",
    "l.url_has_server_in_string()\n",
    "l.url_has_login_in_string()\n",
    "l.url_get_tld()\n",
    "l.url_number_of_subdomains()\n",
    "l.url_number_of_dashes()\n",
    "l.redirection()\n",
    "l.url_have_at_sign()\n",
    "l.is_tiny_url()\n",
    "l.daysSinceRegistration()\n",
    "l.daysSinceExpiration()\n",
    "l.url_number_of_uppercase()\n",
    "l.url_number_of_spaces()\n",
    "l.url_number_of_zeroes()\n",
    "l.is_url_single_character_directory()\n",
    "l.url_ratio_upper_to_lower()\n",
    "l.is_url_in_dns_record()\n",
    "l.url_web_traffic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f1522860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain_name': 'GEEKSFORGEEKS.ORG',\n",
       " 'registrar': 'PDR Ltd. d/b/a PublicDomainRegistry.com',\n",
       " 'whois_server': 'whois.publicdomainregistry.com',\n",
       " 'referral_url': None,\n",
       " 'updated_date': [datetime.datetime(2022, 4, 21, 6, 36, 7),\n",
       "  datetime.datetime(2022, 4, 21, 6, 36, 8)],\n",
       " 'creation_date': datetime.datetime(2009, 3, 19, 6, 8, 55),\n",
       " 'expiration_date': datetime.datetime(2030, 3, 19, 6, 8, 55),\n",
       " 'name_servers': ['NS-1520.AWSDNS-62.ORG',\n",
       "  'NS-1569.AWSDNS-04.CO.UK',\n",
       "  'NS-245.AWSDNS-30.COM',\n",
       "  'NS-869.AWSDNS-44.NET',\n",
       "  'ns-1520.awsdns-62.org',\n",
       "  'ns-1569.awsdns-04.co.uk',\n",
       "  'ns-245.awsdns-30.com',\n",
       "  'ns-869.awsdns-44.net'],\n",
       " 'status': 'clientTransferProhibited https://icann.org/epp#clientTransferProhibited',\n",
       " 'emails': ['abuse@publicdomainregistry.com',\n",
       "  'contact@privacyprotect.org',\n",
       "  'abuse-contact@publicdomainregistry.com'],\n",
       " 'dnssec': ['unsigned', 'Unsigned'],\n",
       " 'name': 'Domain Admin',\n",
       " 'org': 'Privacy Protect, LLC (PrivacyProtect.org)',\n",
       " 'address': '10 Corporate Drive',\n",
       " 'city': 'Burlington',\n",
       " 'state': 'MA',\n",
       " 'zipcode': '01803',\n",
       " 'country': 'US'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0f5bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?><!-- Need more Alexa data?  Find our APIs here: https://aws.amazon.com/marketplace/seller-profile?id=4a9dbf38-88b1-4e87-a459-271154a77d2e --><html><body><alexa aid=\"=\" home=\"0\" idn=\"geeksforgeeks.org/ternary-operator-in-python\" url=\"geeksforgeeks.org/ternary-operator-in-python\" ver=\"0.9\">\n",
       "<sd flags=\"\" host=\"geeksforgeeks.org\" title=\"A\">\n",
       "<title text=\"GeeksforGeeks\"></title>\n",
       "</sd>\n",
       "<sd><popularity source=\"panel\" text=\"205\" url=\"geeksforgeeks.org/\"></popularity><reach rank=\"163\"></reach><rank delta=\"-115\"></rank><country code=\"IN\" name=\"India\" rank=\"58\"></country></sd></alexa></body></html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + l.url).read(),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3663af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e27c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
